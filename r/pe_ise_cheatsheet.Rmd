---
title: "PE ISE Reference Sheet"
author: "Thomas Roh"
date: "January 20, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      fig.align = 'center', 
                      fig.height = 2)
library(ggplot2)
library(data.table)
library(DiagrammeR)
theme_set(trstyles::theme_tr())
```

# Systems Definition, Analysis, and Design

## System Analysis and Design Tools

### Cause-Effect Diagram (Fishbone)

<center>
![](../img/fishbone.png){height="3in"}
</center>

### Pareto Analysis

80% of the items represent 20% of the sales or 20% of the items represent 80% of 
the cost. This law is a rule of thumb.

```{r}
set.seed(42)
items <- paste0("Item ", 1:10)
itemProbs <- c(.6, .2, rep(.025, 8))
nItems <- 10000
itemSamples <- sample(items, nItems, prob = itemProbs, replace = TRUE)
itemTable <- data.table(items = itemSamples)[
  ,.(percent = .N/nItems), by = 'items'][order(percent, decreasing = TRUE)
                                         ][,cumulative := cumsum(percent)][
                                           ,items := factor(items, levels = items)]

ggplot(itemTable) +
  geom_bar(aes(items, percent), stat = 'identity') +
  geom_step(aes(x = as.numeric(items), y = cumulative),
            color = 'red') +
  labs(title = 'Pareto Chart',
       x = "", 
       y = 'Proportion')

```

### Histogram

A bar chart where values are binned into intervals and the count or frequency is
the height of the bars.

```{r}
histData <- rnorm(10000, 100, 10)
qplot(histData, geom = 'histogram', binwidth = 10) +
  labs(title = 'Normal Distribution Sample Data (100, 10)',
       x = 'x')
```

### Scatterplot

A scatterplot is two numeric variables plotted against each other. Often used to 
visually determine if there is correlation.

```{r}

spData <- rnorm(1000, 5, 5)
qplot(spData, spData + rnorm(1000, 0, 3)) +
  labs(title = 'Correlation',
       x = 'x',
       y = 'y')

qplot(spData, rnorm(1000, 5, 5)) +
  labs(title = 'No correlation',
       x = 'x',
       y = 'y')
```

### Operation Process Chart

The operation process chart only has Operations and Inspections.

### Flow Process Chart

The flow process chart forces a more detailed look at a system.

<center>
![ASME standard set of process chart symbols](../img/flow_process_symbols.png){height="1.5in"}
</center>

### Affinity Diagram

organizes a large number of ideas into their natural relationships

### Left Hand Right Hand Chart

Shows when each hand is busy and idle. It is sometimes called a simo chart.

## Modeling Techniques

### Queueing Models

**Effective vs. Offered Load:**

$$\lambda_{eff} = \lambda(1-\pi_m)$$

**Waiting Time Law:**

$$L = \sum_{n=0}^Mn\pi_n$$
$$L_q = \sum_{n=c+1}^{c-1}(n-c)\pi_n$$

**Probability of n arivals by time t:**


$$P[N(t)=n]=\frac{(\lambda t)^ne^{-\lambda t}}{n!}$$
<h5>
$M/M/1/\infty\quad Queue$
</h5>
<hr>

**Probability of customers in system:**

$$\pi_0=1-\rho$$
$$\pi_n=\rho^n(1-\rho)$$
$$L = \frac{\rho}{1-\rho}$$
$$L_q = L-\rho=\frac{\rho^2}{1-\rho}$$
<h5>
$M/G/1/\infty\quad Queue$
</h5>
<hr>

**Pollaczek-Khintchine Formula:**

$$L = L_q+\rho=\frac{\rho^2+\lambda^2\sigma^2}{2(1-\rho)}+\rho$$
<h5>
$M/M/c/M\quad Queue$
</h5>
<hr>

$$D = \sum_{n=0}^{c-1}\frac{\rho^n}{n!}+\frac{\rho^c}{c!}[\frac{1-(\rho/c)^{M-c+1}}{1-\rho/c}]$$
$$\pi_0=\frac{1}{D}$$

$$\pi_n= \begin{cases} 
\frac{\rho^n}{n!}\pi_0, \quad \text{n<c} \\
\frac{\rho^n}{c!c^{n-c}}\pi_0, \quad {n\geq c} 
\end{cases}$$



$$L_q=\pi_0\bigg(\frac{\rho^{c+1}}{(c-1)!(c-\rho)^2}\bigg)
\bigg[1-\big(\frac{\rho}{c}\big)^{M-c}-(M-c)\big(\frac{\rho}{c}\big)^{M-c}\big(1-\frac{\rho}{c}\big)\bigg],\quad \rho\neq c$$

$$L_q=\pi_0\bigg(\frac{\rho^c (M-c)(M-c+1)}{2c!}\bigg),\quad \rho=c$$

$$L_q=\pi_0\bigg(\frac{\rho^{c+1}}{(c-1)!(c-\rho)^2}\bigg),\quad c=\infty$$

<h5>
$M/M/1/M\quad Queue$
</h5>
<hr>
**State probability differential equations:**

$$p'_0(t)=\mu_1p_1(t)-\lambda_0p_0(t) \\
p'_k(t)=\lambda_{k-1}p_{k-1}(t)+\mu_{k+1}p_{k+1}(t)-(\lambda_k+\mu_k)p_{k}(t) \quad for \quad k \le K$$

<h5>
$M/M/C/\infty \quad Queue$
</h5>
<hr>

**C = 1**

$$P_0=1-\rho ,\quad L_q=\frac{\rho^2}{1-\rho}$$

**C = 2**

$$P_0=\frac{(1-\rho)}{(1=\rho}, \quad L_q = \frac{2\rho^3}{(1-\rho^2)}$$

**C = 3**

$$P_0 = \frac{2(1-\rho)}{2+4\rho+3\rho^2}, \quad \frac{9\rho^4}{2+2\rho-\rho^2-3\rho^3}$$



### Linear Programming

**Procedure:**

1. Identify the primary decision variables
2. Identify the constraint linear functions
3. Identify the objective linear function

### Model Verification

A model has been verified if a range of models produce similar results on the 
same situation

### Model Validation

A model has been validated if a range of results produce similar results on 
the same situation


### Bottleneck Analysis

Optimize the process that is the bottleneck, then re-evaulate the bottleneck and
repeat.

# Facilities Engineering and Planning

## People/Equipment Requirements

$$M_j = \sum_{i=1}^{n} \frac{P_{ij}T_{ij}}{C_{ij}} \\ M_j = \textrm{number of machines/people} \\ P = \textrm{production rate} \\ T = \textrm{production time} \\ C = \textrm{production period} \\ n = \textrm{number of products}$$

## Material Handling

**Euclidian:**

$$d = \sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$$
$$min\quad \sum_{i=1}^mw_i[(x-a_i)^2+(y-b_i)]^{\frac{1}{2}}$$
If there are 4 locations with equal weight, the optimal location is the facility 
within a triangle of the other facilities. If there is no such facility, 
the optimal location is at the intersection of two lines.

When the weighted costs are proportional to the square of the Euclidean distance, 
it is called the 'gravity' problem.

$$min\quad \sum_{i=1}^mw_i[(x-a_i)^2+(y-b_i)^2]$$

$$x = \frac{\sum_{i=1}^mw_ia_i}{\sum_{i=1}^mw_i}$$
$$y = \frac{\sum_{i=1}^mw_ib_i}{\sum_{i=1}^mw_i}$$

**Manhattan:**

$$|x_2-x_1| + |y_2-y_1|$$

$$min\quad \sum_{i=1}^m w_i(|x-a_1|+|y-b_i|)$$

The x value is the median of the location x-coordinates.
The y value is the median of the location y-coordinates.

**Chebyshev (simultaneous x and y movement)**

$$max(|x_2-x_1|,|y_2-y_1|)$$

## Relationship Chart

```{r relationship chart}
Code <- c('A', 'E', 'I', 'O', 'U', 'X')
Closeness <- c('Absolutely Necessar', 'Especially Important', 'Important',
               'Ordinary Closeness', 'Unimportant', 'Not desirable')
Rank <- c(.95, .85, .7, .5, 0, "-")
relChart <- data.frame(Code, Closeness, Rank,
                       stringsAsFactors = FALSE)
knitr::kable(relChart)
```

# Supply Chain Logistics

## Forecasting Methods

### Moving Average

$$\hat{d}_t = \frac{\sum_{i=1}^{n}d_{t-i}}{n}$$

### Exponentially Weighted Moving Average

$$\hat{d}_t = \alpha d_{t-1}+(1-\alpha)\hat{d}_{t-1},\quad 0 \leq \alpha( \textrm{smoothing constant})\leq1$$

## Production Planning Methods

**Systems to compute Master Production and Ordering Plan**

Material Requirements Planning (MRP)

Manufacturing Resource Planning (MRPII)

## Engineering Economics

$$\bigg(\frac{F}{P}\bigg)= (1+i)^N$$

$$\bigg(\frac{P}{F}\bigg)= \frac{1}{(1+i)^N}$$

$$\bigg(\frac{F}{A}\bigg)= \frac{(1+i)^N-1}{i}$$


$$\bigg(\frac{P}{A}\bigg)= \frac{(1+i)^N-1}{i(1+i)^N}$$

$$\bigg(\frac{A}{F}\bigg)= \frac{i}{(1+i)^N-1}$$

$$\bigg(\frac{A}{P}\bigg)= \frac{i(1+i)^N}{(1+i)^N-1}$$
*Denominator is current value and Numerator is desired conversion

## Production Scheduling Methods

**Makespan**

the time it takes from the start of the first job until the end of the last job

**Scheduling Sequence**

1. Earliest Due Date - order jobs by due date
2. Shortest Processing Time - order jobs by processing time
3. Critical Ratio - divide time remaining until due date by time left on the 
machine, order by smallest critical ratio

**Johnson's Optimal Rule for Two Machines**

1. Find the shortest processsing times and arbitrarily break ties
2. If the shortest processing time is on Machine A, schedule immediately. If the
shortest processing time is on Machine B, schedule it as late as possible.
3. Eliminate the last job scheduled on the list and repeat step 1-2.

## Inventory Management and Control

### Economic Order Quantity

$$Q^*=\sqrt{\frac{2C_pD}{h}R} \\ R = \frac{1}{1-\frac{D}{P}},\quad\textrm{R=1, when replenishment is instaneous} \\ D=\textrm{demand},P=\textrm{production rate},C_p=\textrm{cost per order},h=\textrm{holding cost}$$

### Economic Manufacturing Quantity

Use the equation above with R not equal to 1.

### With shortage costs

$$Q^* = \sqrt{\frac{2C_pD}{h}R\big(\frac{h+z}{z}\big)} \\ z = \textrm{shortage cost}$$

$$M^*=\sqrt{\frac{2C_pD(1-\frac{D}{P})h}{z(h+z)}} \\ M = \textrm{allowed shortage}$$

### Carrying Cost

$$C_T=\frac{hQ}{2}\big(1-\frac{D}{P}\big)+CD+C_p\frac{D}{Q}$$

### Probabilistic Inventory and Production Models

$$F_D(x=y^*)\ge\frac{p-c}{p+h} \\ F_D = \textrm{CDF} \\ x = \textrm{units on hand}, y^*=\textrm{optimal order quantity}, p = \textrm{loss of potential revenue},\\ h = \textrm{loss in value from holding}, c = \textrm{unit acquisition cost}$$

## Distribution Methods

**Transhipment:**

The intermediary storage

### Transportation Problem

$$min \quad \sum_{i=1}^m \sum_{j=1}^nx_{ij}c_{ij} \\ \sum_{j=1}^nx_{ij}=s_i, n = 1, 2, ..., m \\ \sum_{i=1}^mx_{ij}=d_j, m = 1, 2, ..., n$$

### Storage and Warehousing Methods

1. Dedicated Storage
    * easy to retrieve items
    * Sum of maximum of each product
2. Random Storage
    * more efficient use of space
    * Maximum of the sums of all products

    
## Transportation Modes

1. Variable Path
    * truck, vehicle anything that does not have one fixed path
    * versatility
2. Fixed Path
    * conveyor
    * tied to one path
    
## Assignment Problem

**Hungarian Procedure:**

1. Subtract the minimum of the row from all elements in the row
2. Substract the minimum of the column from all elements in the columns
3. Try to make a valid assignment using the zero elements, if all assigments 
cannot be made proceed to next step
4. Cover all zeroes with the minimal number of lines
5. From each uncovered element subtract the minimum of the uncovered *y*, 
add *y* to each intersection element. Go to step 3.
6. Transfer the assignment plan to the original cost table.

# Work Design

## Noise Dose

**Dose**

$$D=100*\big(\frac{C_1}{T_1}+\frac{C_2}{T_2}+...+\frac{C_n}{T_n}\big)\le 100$$

**Time Weighted Average**

$$TWA=16.61log_{10}\big(\frac{D}{100}\big)+90$$

## Exposure

**Time Weighted Concentration**

$$TWA=\frac{\sum_{i=1}^nC_iT_i}{\sum_{i=1}^nT_i}$$


## Taylor Tool Life

$$VT^n=C \\ V = \textrm{speed surface feet per minute} \\ T = \textrm{tool life in minutes} \\ C,n = \textrm{constants that depend on material and tool}$$

## Work Sampling

$$D = Z_{\alpha/2}\sqrt{\frac{p(-1-p)}{n}}, \quad Z_{\alpha/2}\sqrt{\frac{1-p}{pn}} \\ p = \textrm{proportion of observed time} \\ D = \textrm{absolute error} \\ R = \textrm{relative error} = \frac{D}{p} \\ n = \textrm{sample size}$$

## Critical Path Method

$$T = \sum_{(i,j)\in CP}d_{ij}$$

## Standard Time

$$\textrm{Observed Time * Pace Rating * (1 + personal time allowance) * (1 + fatigue allowance)}$$

## Recommended Weight Limit

Units are pounds and inches.

$$RWL = 51(10/H)(1-.0075|V-30|)(.82+\frac{1.8}{D}(1-.0032A)FM*CM \\ \textrm{H = horizontal location of the load forward of the midpoint of the ankles} \\ \textrm{V = vertical location of the load} \\ \textrm{D = Vertical travel distance between the origin and the destination} \\ \textrm{A=angle of asymmetry between hands and feet} \\ \textrm{FM = frequency multiplier (from table)} \\ \textrm{CM = coupling mulitiplier (from table)}$$

## Learning Curve

$$y=kx^n, n=\frac{log_{e}\phi}{log_{e}(2)} \\ \phi=\textrm{learning ratio}=\frac{T(2N)}{T(N)}, \textrm{T(N) = time to produce Nth unit} \\ \textrm{y=total time, k = time to produce first unit, x = number of units produced}$$

**Total Learning Time:**

$$T=k\frac{[(x_2+\frac{1}{2})^{n+1}-(x_1+\frac{1}{2})^{n+1}]}{n+1}$$

**Remission Line:**

$$y=k+\frac{(k-s)(x-1)}{1-x_s}$$

# Quality Control

## Statistical Process Control

### X & R-Chart

$$UCL = D_4\bar{R} \\ CL = \bar{R} \\ LCL = D_3\bar{R}$$

$$UCL = \bar{\bar{X}}+A_2\bar{R} \\ CL = \bar{\bar{X}} \\ LCL = \bar{\bar{X}}-A_2\bar{R}$$

### X & S-Chart

$$UCL=B_4\bar{S} \\ CL = \bar{X} \\ LCL = B_3\bar{S}$$

$$UCL = \bar{\bar{X}} + A_3\bar{S} \\ CL = \bar{\bar{X}} \\ LCL = \bar{\bar{X}}-A_3\bar{S}$$

### P-Chart

$$UCL = \bar{p}+3\sqrt{\frac{\bar{p}(1-\bar{p})}{n}} \\ CL = \bar{p} \\ LCL = \bar{p} - 3\sqrt{\frac{\bar{p}(1-\bar{p})}{n}}$$

### C-Chart

$$UCL = \bar{c}+3\sqrt{\bar{c}} \\ CL = \bar{c} \\ LCL = \bar{c}-3\sqrt{\bar{c}}$$

### Tests for Out of Control

1. A single point falls outside three sigma control limits
2. Two out of three successive points fall on the same side of and more than two 
sigma units from the center line
3. Four out of five successive points fall on the same side of and more than 
one sigma unit from the center line
4. Eight successive points fall on the same side of the center line

## Control vs. Capability

In control if it is within natural variability

Is capable if it is entirely within specification

## Process Capability

**Actual Capability:**

$$C_{pk}=min\bigg(\frac{\mu-LSL}{3\sigma},\frac{USL-\mu}{3\sigma}\bigg)$$

**Potential Capability:**

$$C_p = \frac{USL-LSL}{6\sigma}$$

## Reliability Analysis

**Series:**

$$R = \prod_{i=1}^n P_i$$

**Parallel:**

$$R = 1-\prod_{i=1}^n (1-P_i) $$

# Statistics

## Normal Distribution

**z-score**

$$z=\frac{x-\mu}{\sigma}$$

**Confidence Interval**

$$\bar{x}\pm\frac{z_{\alpha/2} \sigma}{\sqrt{n}}$$

**Two-means comparison:**

$$z_0=\frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}$$

## student-t Distribution

**t-score:**

$$t=\frac{\bar{x}-\mu}{\frac{s}{\sqrt{n}}}$$

**Confidence Interval**

$$\bar{x}\pm\frac{t_{\alpha/2,n-1}s}{\sqrt{n}}$$

**Two-means comparison:**

$$t_0=\frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$$

**df for Two Sample t-test:**

$$df=\frac{\big(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}\big)^2}{\frac{(\frac{s_1^2}{n_1})^2}{n_1-1}+{\frac{(\frac{s_1^2}{n_1})^2}{n_1-1}}}$$

## Chi-Squared Goodness of Fit

$$\chi^2=\sum_{j=1}^k\frac{(O_j-E_j)^2}{E_j}$$

## Linear Regression


$$SSR=\sum_{i=1}^n(\hat{y}_i-\bar{y})^2$$

$$SSE = \sum_{i=1}^n(y_i-\hat{y}_i)^2$$

$$SST = \sum_{i=1}^n(y_i-\bar{y})^2$$

$$R^2=\frac{SSR}{SST} = 1-\frac{SSE}{SST}$$

## ANOVA

$$SSA+SSE=SST$$

### ANOVA Table

**One-Way**

Given Treatment A:

$$SSA+SSE=SST$$

```{r oneway ANOVA}
SS <- c('SSA', 'SSE', 'SST')
df <- c('a-1', 'a(n-1)', 'an-1')
MS <- c('SSA/dfA', 'SSE/dfE', '')
fstat <- c('MSA/MSE', '', '')
anovaTable <- data.frame(SS,
                         df,
                         MS,
                         "F" = fstat)
knitr::kable(anovaTable)
```

**Two-Way**

Given treatment factors A & B:

$$SST=SSA+SSB+SSAB+SSE$$

```{r twoway ANOVA}
SS <- c('SSA', 'SSB', 'SSAB', 'SSE', 'SST')
df <- c('a-1', 'b-1', '(a-1)(b-1)', 'ab(n-1)', 'abn-1')
MS <- c('SSA/dfA', 'SSB/dfB', 'SSAB/dfAB', 'SSE/dfE', '')
fstat <- c('MSA/MSE', 'MSB/MSE', 'MSAB/MSE', '', '')
anovaTable <- data.frame(SS,
                         df,
                         MS,
                         "F" = fstat)
knitr::kable(anovaTable)
```

## Distributions

### Discrete

$$
\begin{array}{c|c|c|c}
\text{Distribution}& \text{pmf} & \text{cdf} & \text{mean} & \text{variance} & \text{parameters} \\
\hline
\text{Binomial} & 
\binom{n}{k}p^k(1-p)^{n-k} & 
\sum_{i=0}^{\lfloor k \rfloor}\binom{n}{i}p^i(1-p)^{n-i} & 
np & 
np(1-p) &
\text{n = number of trials, p = success probability}  \\ \hline
\text{Discrete Uniform} & 
\frac{1}{b-a+1} & 
\frac{\lfloor k \rfloor - a + 1}{b-a+1} & 
\frac{a+b}{2} & 
\frac{(b-a+1)^2-1}{12} & 
\text{a = minimum, b = maximum} \\ \hline
\text{Poisson} & 
\frac{\lambda^k e^{-\lambda}}{k!} & 
e^{-\lambda}\sum_{i=0}^{\lfloor k \rfloor}\frac{\lambda^i}{i!} & 
\lambda & 
\lambda & 
\lambda\text{ = rate} \\ \hline
\text{Geometric} & 
p(1-p)^{k-1} & 
1-(1-p)^k & 
\frac{1}{p} & 
\frac{1-p}{p^2} & 
\text{k = number of trials, p = success probability}
\end{array}
$$

### Continuous

$$
\begin{array}{c|c|c|c}
\text{Distribution}& \text{pdf} & \text{cdf} & \text{mean} & \text{variance} & \text{parameters} \\
\hline
\text{Uniform} & 
\frac{1}{b-a} & 
\frac{x-a}{b-a} & 
\frac{a+b}{2} & 
\frac{(b-a)^2}{12} &
\text{a = minimum, b = maximum} \\ \hline
\text{Exponential} & 
\lambda e^{-\lambda x} & 
1-e^{-\lambda x} & 
\frac{1}{\lambda} & 
\frac{1}{\lambda^2} & 
\lambda \text{ = rate} \\ \hline
\text{Normal} & 
\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} & 
\frac{1}{2}\big[1+erf\big(\frac{x-\mu}{\sigma\sqrt{2}}\big)\big] & 
\mu & 
\sigma^2 & 
\mu \text{ = mean, } \sigma^2 \text{ = variance} \\ \hline
\text{PERT beta} & 
undefined & 
undefined & 
\frac{a+4m+b}{6} & 
\frac{(b-a)^2}{36} & 
\text{a = 1st percentile, b = 99th percentile, m = mode} \\ \hline
\text{Triangular} & 
\begin{cases}
\frac{(x-a)^2}{(b-a)(c-a)},\quad a\le x\le c \\
1-\frac{(b-x)^2}{(b-a)(b-c)},\quad c<x\le b
\end{cases} &
\begin{cases}
\frac{(x-a)^2}{(b-a)(c-a)},\quad a\le x\le c \\
1-\frac{(b-x)^2}{(b-a)(b-c)}, \quad c<x\le b
\end{cases} & 
\frac{a+b+c}{3} & 
\frac{a^2+m^2+b^2-ca-ab-cb}{18} & 
\text{a = minimum, b = maximum, c = mode} \\ \hline
\text{Gamma} & 
\frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x} & 
\frac{1}{\Gamma(\alpha)}\gamma(\alpha,\beta x) & 
\alpha\beta & 
\alpha\beta^2 & 
\alpha \text{ = shape, } \beta \text{ = scale} \\ \hline
\text{Weibull} & 
\frac{k}{\lambda}\binom{x}{\lambda}^{k-1}e^{-{(\frac{x}{\lambda}})^k} &
1-e^{-(\frac{x}{\lambda})^k} & 
 & 
 & 
 \\ \hline
\text{Lognormal} & 
\frac{1}{x\sigma\sqrt{2\pi}}e^{\frac{(ln x-\mu)^2}{2\sigma^2}} & 
\frac{1}{2}+ \frac{1}{2} erf \big[ \frac{ln x-\mu}{\sigma\sqrt{2}}\big]& 
e^{\mu+\frac{\sigma^2}{2}} & 
[e^{\sigma^2}-1] e^{2\mu+\sigma^2} & 
\mu\text{ = mean, } \sigma^2 \text{ = variance}
\end{array}
$$


## Factors for Control Charts

```{r fcc, echo = FALSE}
ccf <- read.csv('../data/control_chart_factors.csv')
names(ccf) <- sub("([0-9]{1})", "_\\1", names(ccf))
knitr::kable(ccf, format = 'latex', align = 'c')
```

$$
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
n & A & A_2 & A_3 & c_4 & B_3 & B_4 & B_5 & B_6 & d_2 & \frac{1}{d_2} & d_3 & D_1 & D_2 & D_3 & D_4\\
\hline
2 & 2.121 & 1.880 & 2.659 & 0.7979 & 0.000 & 3.267 & 0.000 & 2.606 & 1.128 & 0.8862 & 0.853 & 0.000 & 3.686 & 0.000 & 3.267\\
\hline
3 & 1.732 & 1.023 & 1.954 & 0.8862 & 0.000 & 2.568 & 0.000 & 2.276 & 1.693 & 0.5908 & 0.888 & 0.000 & 4.358 & 0.000 & 2.575\\
\hline
4 & 1.500 & 0.729 & 1.628 & 0.9213 & 0.000 & 2.266 & 0.000 & 2.088 & 2.059 & 0.4857 & 0.880 & 0.000 & 4.698 & 0.000 & 2.282\\
\hline
5 & 1.342 & 0.577 & 1.427 & 0.9400 & 0.000 & 2.089 & 0.000 & 1.964 & 2.326 & 0.4299 & 0.864 & 0.000 & 4.918 & 0.000 & 2.114\\
\hline
6 & 1.225 & 0.483 & 1.287 & 0.9515 & 0.030 & 1.970 & 0.029 & 1.874 & 2.534 & 0.3946 & 0.848 & 0.000 & 5.079 & 0.000 & 2.004\\
\hline
7 & 1.134 & 0.419 & 1.182 & 0.9594 & 0.118 & 1.882 & 0.113 & 1.806 & 2.704 & 0.3698 & 0.833 & 0.205 & 5.204 & 0.076 & 1.924\\
\hline
8 & 1.061 & 0.373 & 1.099 & 0.9650 & 0.185 & 1.815 & 0.179 & 1.751 & 2.847 & 0.3512 & 0.820 & 0.388 & 5.307 & 0.136 & 1.864\\
\hline
9 & 1.000 & 0.337 & 1.032 & 0.9693 & 0.239 & 1.761 & 0.232 & 1.707 & 2.970 & 0.3367 & 0.808 & 0.547 & 5.394 & 0.184 & 1.816\\
\hline
10 & 0.949 & 0.308 & 0.975 & 0.9727 & 0.284 & 1.716 & 0.276 & 1.669 & 3.078 & 0.3249 & 0.797 & 0.686 & 5.469 & 0.223 & 1.777\\
\hline
11 & 0.905 & 0.285 & 0.927 & 0.9754 & 0.321 & 1.679 & 0.313 & 1.637 & 3.173 & 0.3152 & 0.787 & 0.811 & 5.535 & 0.256 & 1.744\\
\hline
12 & 0.866 & 0.266 & 0.886 & 0.9776 & 0.354 & 1.646 & 0.346 & 1.610 & 3.258 & 0.3069 & 0.778 & 0.923 & 5.594 & 0.283 & 1.717\\
\hline
13 & 0.832 & 0.249 & 0.850 & 0.9794 & 0.382 & 1.618 & 0.374 & 1.585 & 3.336 & 0.2998 & 0.770 & 1.025 & 5.647 & 0.307 & 1.693\\
\hline
14 & 0.802 & 0.235 & 0.817 & 0.9810 & 0.406 & 1.594 & 0.399 & 1.563 & 3.407 & 0.2935 & 0.763 & 1.118 & 5.696 & 0.328 & 1.672\\
\hline
15 & 0.775 & 0.223 & 0.789 & 0.9823 & 0.428 & 1.572 & 0.421 & 1.544 & 3.472 & 0.2880 & 0.756 & 1.203 & 5.740 & 0.347 & 1.653\\
\hline
16 & 0.750 & 0.212 & 0.763 & 0.9835 & 0.448 & 1.552 & 0.440 & 1.526 & 3.532 & 0.2831 & 0.750 & 1.282 & 5.782 & 0.363 & 1.637\\
\hline
17 & 0.728 & 0.203 & 0.739 & 0.9845 & 0.466 & 1.534 & 0.458 & 1.511 & 3.588 & 0.2787 & 0.744 & 1.356 & 5.820 & 0.378 & 1.622\\
\hline
18 & 0.707 & 0.194 & 0.718 & 0.9854 & 0.482 & 1.518 & 0.475 & 1.496 & 3.640 & 0.2747 & 0.739 & 1.424 & 5.856 & 0.391 & 1.609\\
\hline
19 & 0.688 & 0.187 & 0.698 & 0.9862 & 0.497 & 1.503 & 0.490 & 1.483 & 3.689 & 0.2711 & 0.733 & 1.489 & 5.889 & 0.404 & 1.596\\
\hline
20 & 0.671 & 0.180 & 0.680 & 0.9869 & 0.510 & 1.490 & 0.504 & 1.470 & 3.735 & 0.2677 & 0.729 & 1.549 & 5.921 & 0.415 & 1.585\\
\hline
21 & 0.655 & 0.173 & 0.663 & 0.9876 & 0.523 & 1.477 & 0.516 & 1.459 & 3.778 & 0.2647 & 0.724 & 1.606 & 5.951 & 0.425 & 1.575\\
\hline
22 & 0.640 & 0.167 & 0.647 & 0.9882 & 0.534 & 1.466 & 0.528 & 1.448 & 3.819 & 0.2618 & 0.720 & 1.660 & 5.979 & 0.435 & 1.565\\
\hline
23 & 0.626 & 0.162 & 0.633 & 0.9887 & 0.545 & 1.455 & 0.539 & 1.438 & 3.858 & 0.2592 & 0.716 & 1.711 & 6.006 & 0.443 & 1.557\\
\hline
24 & 0.612 & 0.157 & 0.619 & 0.9892 & 0.555 & 1.445 & 0.549 & 1.429 & 3.895 & 0.2567 & 0.712 & 1.759 & 6.032 & 0.452 & 1.548\\
\hline
25 & 0.600 & 0.153 & 0.606 & 0.9896 & 0.565 & 1.435 & 0.559 & 1.420 & 3.931 & 0.2544 & 0.708 & 1.805 & 6.056 & 0.459 & 1.541\\
\end{array}
$$

## Normal Distribution

```{r}
normalTable <- matrix(round(pnorm(seq(0, 3.09, by = .01)), 4), ncol = 10)
colnames(normalTable) <- seq(0, .09, by = .01)
rownames(normalTable) <- sprintf("%01.1f", seq(0, 3, by = .1))
knitr::kable(normalTable)
```

## t-Distribution

```{r}
alpha <- c(.1, .05, .025, .01, .005)
v <- c(seq(1, 30, by = 1), Inf)
tTable <- sapply((1-alpha), function(x) qt(x, df = v))
colnames(tTable) <- alpha
rownames(tTable) <- v
knitr::kable(tTable, row.names = TRUE)
```
<h2>
$$\chi^2 \quad Distribution$$
</h2>

```{r}
alpha <- c(.995, .99, .975, .95, .9, .75, .5, .25, .1, .05, .025, .01, .005, .001)
v <- seq(1, 100, by = 1)
chiTable <- sapply((1-alpha), function(x) round(qchisq(x, df = v), 2))
colnames(chiTable) <- alpha
rownames(chiTable) <- v
knitr::kable(chiTable, row.names = TRUE)
```

<h2>
$$
F(v_1, v_2)
$$
</h2>

### 95th Percentiles

```{r}
v1 <- c(seq(1, 10, by = 1), 12, 15, 20, 24, 30, 40, 60, 120, Inf)
v2 <- v1
fTable95 <- sapply(v1, function(x) signif(qf(.95, x, v2), 3))
colnames(fTable95) <- v1
rownames(fTable95) <- v2
knitr::kable(fTable95, row.names = TRUE)
```

### 99th Percentiles

```{r}
v1 <- c(seq(1, 10, by = 1), 12, 15, 20, 24, 30, 40, 60, 120, Inf)
v2 <- v1
fTable99 <- sapply(v1, function(x) signif(qf(.99, x, v2), 3))
colnames(fTable99) <- v1
rownames(fTable99) <- v2
knitr::kable(fTable99, row.names = TRUE)
```

