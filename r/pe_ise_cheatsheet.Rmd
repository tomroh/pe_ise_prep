---
title: "PE ISE Reference Sheet"
author: "Thomas Roh"
date: "January 20, 2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      fig.align = 'center', 
                      fig.height = 2)
library(ggplot2)
library(data.table)
library(DiagrammeR)
library(xtable)
theme_set(trstyles::theme_tr())
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

# Systems Definition, Analysis, and Design

## System Analysis and Design Tools

### Cause-Effect Diagram (Fishbone)

<center>
![](../img/fishbone.png){height="3in"}
</center>

### Pareto Analysis

80% of the items represent 20% of the sales or 20% of the items represent 80% of 
the cost. This law is a rule of thumb.

```{r}
set.seed(42)
items <- paste0("Item ", 1:10)
itemProbs <- c(.6, .2, rep(.025, 8))
nItems <- 10000
itemSamples <- sample(items, nItems, prob = itemProbs, replace = TRUE)
itemTable <- data.table(items = itemSamples)[
  ,.(percent = .N/nItems), by = 'items'][order(percent, decreasing = TRUE)
                                         ][,cumulative := cumsum(percent)][
                                           ,items := factor(items, levels = items)]

ggplot(itemTable) +
  geom_bar(aes(items, percent), stat = 'identity') +
  geom_step(aes(x = as.numeric(items), y = cumulative),
            color = 'red') +
  labs(title = 'Pareto Chart',
       x = "", 
       y = 'Proportion')

```

### Operation Process Chart

The operation process chart only has Operations and Inspections.

### Flow Process Chart

The flow process chart forces a more detailed look at a system.

<center>
![ASME standard set of process chart symbols](../img/flow_process_symbols.png){height="1.5in"}
</center>

### Affinity Diagram

organizes a large number of ideas into their natural relationships

### Left Hand Right Hand Chart

Shows when each hand is busy and idle. It is sometimes called a simo chart.

## Modeling Techniques

### Queueing Models

<h5>
$M/M/c/K\quad Queue$
</h5>
<hr>

**Effective vs. Offered Load:**

$$\lambda_{eff} = \lambda(1-\pi_m)$$

**Waiting Time Law:**

$$L = \sum_{n=0}^Mn\pi_n$$
$$L_q = \sum_{n=c+1}^{c-1}(n-c)\pi_n$$

**Probability of n arivals by time t:**


$$P[N(t)=n]=\frac{(\lambda t)^ne^{-\lambda t}}{n!}$$
<h5>
$M/M/1/\infty\quad Queue$
</h5>
<hr>

**Probability of customers in system:**

$$\pi_0=1-\rho$$
$$\pi_n=\rho^n(1-\rho)$$
$$L = \frac{\rho}{1-\rho}$$
$$L_q = L-\rho=\frac{\rho^2}{1-\rho}$$
<h5>
$M/G/1/\infty\quad Queue$
</h5>
<hr>

**Pollaczek-Khintchine Formula:**

$$L = L_q+\rho=\frac{\rho^2+\lambda^2\sigma^2}{2(1-\rho)}+\rho$$
<h5>
$M/M/c/M\quad Queue$
</h5>
<hr>

$$D = \sum_{n=0}^{c-1}\frac{\rho^n}{n!}+\frac{\rho^c}{c!}[\frac{1-(\rho/c)^{M-c+1}}{1-\rho/c}]$$
$$\pi_0=\frac{1}{D}$$

$$\pi_n= \begin{cases} 
\frac{\rho^n}{n!}\pi_0, \quad \text{n<c} \\
\frac{\rho^n}{c!c^{n-c}}\pi_0, \quad {n\geq c} 
\end{cases}$$



$$L_q=\pi_0\bigg(\frac{\rho^{c+1}}{(c-1)!(c-\rho)^2}\bigg)
\bigg[1-\big(\frac{\rho}{c}\big)^{M-c}-(M-c)\big(\frac{\rho}{c}\big)^{M-c}\big(1-\frac{\rho}{c}\big)\bigg],\quad \rho\neq c$$

$$L_q=\pi_0\bigg(\frac{\rho^c (M-c)(M-c+1)}{2c!}\bigg),\quad \rho=c$$

$$L_q=\pi_0\bigg(\frac{\rho^{c+1}}{(c-1)!(c-\rho)^2}\bigg),\quad c=\infty$$

<h5>
$M/M/1/M\quad Queue$
</h5>
<hr>
**State probability differential equations:**

$$p_0^\prime(t)=\mu_1p_1(t)-\lambda_0p_0(t) \\
p_k^\prime(t)=\lambda_{k-1}p_{k-1}(t)+\mu_{k+1}p_{k+1}(t)-(\lambda_k+\mu_k)p_{k}(t) \quad for \quad k \le K$$

<h5>
$M/M/C/\infty \quad Queue$
</h5>
<hr>

**C = 1**

$$P_0=1-\rho ,\quad L_q=\frac{\rho^2}{1-\rho}$$

**C = 2**

$$P_0=\frac{(1-\rho)}{(1=\rho}, \quad L_q = \frac{2\rho^3}{(1-\rho^2)}$$

**C = 3**

$$P_0 = \frac{2(1-\rho)}{2+4\rho+3\rho^2}, \quad \frac{9\rho^4}{2+2\rho-\rho^2-3\rho^3}$$



### Linear Programming

**Procedure:**

1. Identify the primary decision variables
2. Identify the constraint linear functions
3. Identify the objective linear function

### Model Verification

A model has been verified if a range of models produce similar results on the 
same situation

### Model Validation

A model has been validated if a range of results produce similar results on 
the same situation


### Bottleneck Analysis

Optimize the process that is the bottleneck, then re-evaulate the bottleneck and
repeat.

# Facilities Engineering and Planning

## People/Equipment Requirements

$$M_j = \sum_{i=1}^{n} \frac{P_{ij}T_{ij}}{C_{ij}} \\ M_j = \textrm{number of machines/people} \\ P = \textrm{production rate} \\ T = \textrm{production time} \\ C = \textrm{production period} \\ n = \textrm{number of products}$$

## Material Handling

**Euclidian:**

$$d = \sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$$
$$min\quad \sum_{i=1}^mw_i[(x-a_i)^2+(y-b_i)]^{\frac{1}{2}}$$
If there are 4 locations with equal weight, the optimal location is the facility 
within a triangle of the other facilities. If there is no such facility, 
the optimal location is at the intersection of two lines.

When the weighted costs are proportional to the square of the Euclidean distance, 
it is called the 'gravity' problem.

$$min\quad \sum_{i=1}^mw_i[(x-a_i)^2+(y-b_i)^2]$$

$$x = \frac{\sum_{i=1}^mw_ia_i}{\sum_{i=1}^mw_i}$$
$$y = \frac{\sum_{i=1}^mw_ib_i}{\sum_{i=1}^mw_i}$$

**Manhattan:**

$$|x_2-x_1| + |y_2-y_1|$$

$$min\quad \sum_{i=1}^m w_i(|x-a_1|+|y-b_i|)$$

The x value is the median of the location x-coordinates.
The y value is the median of the location y-coordinates.

**Chebyshev (simultaneous x and y movement)**

$$max(|x_2-x_1|,|y_2-y_1|)$$

## Relationship Chart

```{r relationship chart}
Code <- c('A', 'E', 'I', 'O', 'U', 'X')
Closeness <- c('Absolutely Necessary', 'Especially Important', 'Important',
               'Ordinary Closeness', 'Unimportant', 'Not desirable')
Rank <- c(.95, .85, .7, .5, 0, "-")
relChart <- data.frame(Code, Closeness, Rank,
                       stringsAsFactors = FALSE)
knitr::kable(relChart)
```

# Supply Chain Logistics

## Forecasting Methods

### Moving Average

$$\hat{d}_t = \frac{\sum_{i=1}^{n}d_{t-i}}{n}$$

### Exponentially Weighted Moving Average

$$\hat{d}_t = \alpha d_{t-1}+(1-\alpha)\hat{d}_{t-1},\quad 0 \leq \alpha( \textrm{smoothing constant})\leq1$$

## Production Planning Methods

**Systems to compute Master Production and Ordering Plan**

Material Requirements Planning (MRP)

Manufacturing Resource Planning (MRPII)

## Engineering Economics

$$\bigg(\frac{F}{P}\bigg)= (1+i)^N, \quad 
\bigg(\frac{P}{F}\bigg)= \frac{1}{(1+i)^N} 
\\
\bigg(\frac{F}{A}\bigg)= \frac{(1+i)^N-1}{i}, \quad
\bigg(\frac{P}{A}\bigg)= \frac{(1+i)^N-1}{i(1+i)^N} 
\\
\bigg(\frac{A}{F}\bigg)= \frac{i}{(1+i)^N-1}, \quad
\bigg(\frac{A}{P}\bigg)= \frac{i(1+i)^N}{(1+i)^N-1}$$

*Denominator is current value and Numerator is desired conversion

## Production Scheduling Methods

**Makespan**

the time it takes from the start of the first job until the end of the last job

**Scheduling Sequence**

1. Earliest Due Date - order jobs by due date
2. Shortest Processing Time - order jobs by processing time
3. Critical Ratio - divide time remaining until due date by time left on the 
machine, order by smallest critical ratio

**Johnson's Optimal Rule for Two Machines**

1. Find the shortest processsing times and arbitrarily break ties
2. If the shortest processing time is on Machine A, schedule immediately. If the
shortest processing time is on Machine B, schedule it as late as possible.
3. Eliminate the last job scheduled on the list and repeat step 1-2.

## Inventory Management and Control

### Economic Order Quantity

$$Q^*=\sqrt{\frac{2C_pD}{h}R} \\ R = \frac{1}{1-\frac{D}{P}},\quad\textrm{R=1, when replenishment is instaneous} \\ D=\textrm{demand},P=\textrm{production rate},C_p=\textrm{cost per order},h=\textrm{holding cost}$$

### Economic Manufacturing Quantity

Use the equation above with R not equal to 1.

### With shortage costs

$$Q^* = \sqrt{\frac{2C_pD}{h}R\big(\frac{h+z}{z}\big)} \\ z = \textrm{shortage cost}$$

$$M^*=\sqrt{\frac{2C_pD(1-\frac{D}{P})h}{z(h+z)}} \\ M = \textrm{allowed shortage}$$

### Carrying Cost

$$C_T=\frac{hQ}{2}\big(1-\frac{D}{P}\big)+CD+C_p\frac{D}{Q}$$

### Probabilistic Inventory and Production Models

$$F_D(x=y^*)\ge\frac{p-c}{p+h} \\ F_D = \textrm{CDF} \\ x = \textrm{units on hand}, y^*=\textrm{optimal order quantity}, p = \textrm{loss of potential revenue},\\ h = \textrm{loss in value from holding}, c = \textrm{unit acquisition cost}$$

## Distribution Methods

**Transhipment:**

The intermediary storage

### Transportation Problem

$$min \quad \sum_{i=1}^m \sum_{j=1}^nx_{ij}c_{ij} \\ \sum_{j=1}^nx_{ij}=s_i, n = 1, 2, ..., m \\ \sum_{i=1}^mx_{ij}=d_j, m = 1, 2, ..., n$$

### Storage and Warehousing Methods

1. Dedicated Storage
    * easy to retrieve items
    * Sum of maximum of each product
2. Random Storage
    * more efficient use of space
    * Maximum of the sums of all products

    
## Transportation Modes

1. Variable Path
    * truck, vehicle anything that does not have one fixed path
    * versatility
2. Fixed Path
    * conveyor
    * tied to one path
    
## Assignment Problem

**Hungarian Procedure:**

1. Subtract the minimum of the row from all elements in the row
2. Substract the minimum of the column from all elements in the columns
3. Try to make a valid assignment using the zero elements, if all assigments 
cannot be made proceed to next step
4. Cover all zeroes with the minimal number of lines
5. From each uncovered element subtract the minimum of the uncovered *y*, 
add *y* to each intersection element. Go to step 3.
6. Transfer the assignment plan to the original cost table.

# Work Design

## Noise Dose

**Dose**

$$D=100*\big(\frac{C_1}{T_1}+\frac{C_2}{T_2}+...+\frac{C_n}{T_n}\big)\le 100$$

**Time Weighted Average**

$$TWA=16.61log_{10}\big(\frac{D}{100}\big)+90$$

## Exposure

**Time Weighted Concentration**

$$TWA=\frac{\sum_{i=1}^nC_iT_i}{\sum_{i=1}^nT_i}$$


## Taylor Tool Life

$$VT^n=C \\ V = \textrm{speed surface feet per minute} \\ T = \textrm{tool life in minutes} \\ C,n = \textrm{constants that depend on material and tool}$$

## Work Sampling

$$D = Z_{\alpha/2}\sqrt{\frac{p(-1-p)}{n}}, \quad Z_{\alpha/2}\sqrt{\frac{1-p}{pn}} \\ p = \textrm{proportion of observed time} \\ D = \textrm{absolute error} \\ R = \textrm{relative error} = \frac{D}{p} \\ n = \textrm{sample size}$$

## Critical Path Method

$$T = \sum_{(i,j)\in CP}d_{ij}$$

## Standard Time

$$\textrm{Observed Time * Pace Rating * (1 + personal time allowance) * (1 + fatigue allowance)}$$

## Recommended Weight Limit

Units are pounds and inches.

$$RWL = 51(10/H)(1-.0075|V-30|)(.82+\frac{1.8}{D}(1-.0032A)FM*CM \\ \textrm{H = horizontal location of the load forward of the midpoint of the ankles} \\ \textrm{V = vertical location of the load} \\ \textrm{D = Vertical travel distance between the origin and the destination} \\ \textrm{A=angle of asymmetry between hands and feet} \\ \textrm{FM = frequency multiplier (from table)} \\ \textrm{CM = coupling mulitiplier (from table)}$$

## Learning Curve

$$y=kx^n, n=\frac{log_{e}\phi}{log_{e}(2)} \\ \phi=\textrm{learning ratio}=\frac{T(2N)}{T(N)}, \textrm{T(N) = time to produce Nth unit} \\ \textrm{y=total time, k = time to produce first unit, x = number of units produced}$$

**Total Learning Time:**

$$T=k\frac{[(x_2+\frac{1}{2})^{n+1}-(x_1+\frac{1}{2})^{n+1}]}{n+1}$$

**Remission Line:**

$$y=k+\frac{(k-s)(x-1)}{1-x_s}$$

# Quality Control

## Statistical Process Control

### X & R-Chart

$$UCL = D_4\bar{R} \\ CL = \bar{R} \\ LCL = D_3\bar{R}$$

$$UCL = \bar{\bar{X}}+A_2\bar{R} \\ CL = \bar{\bar{X}} \\ LCL = \bar{\bar{X}}-A_2\bar{R}$$

### X & S-Chart

$$UCL=B_4\bar{S} \\ CL = \bar{X} \\ LCL = B_3\bar{S}$$

$$UCL = \bar{\bar{X}} + A_3\bar{S} \\ CL = \bar{\bar{X}} \\ LCL = \bar{\bar{X}}-A_3\bar{S}$$

### P-Chart

$$UCL = \bar{p}+3\sqrt{\frac{\bar{p}(1-\bar{p})}{n}} \\ CL = \bar{p} \\ LCL = \bar{p} - 3\sqrt{\frac{\bar{p}(1-\bar{p})}{n}}$$

### C-Chart

$$UCL = \bar{c}+3\sqrt{\bar{c}} \\ CL = \bar{c} \\ LCL = \bar{c}-3\sqrt{\bar{c}}$$

### Tests for Out of Control

1. A single point falls outside three sigma control limits
2. Two out of three successive points fall on the same side of and more than two 
sigma units from the center line
3. Four out of five successive points fall on the same side of and more than 
one sigma unit from the center line
4. Eight successive points fall on the same side of the center line

## Control vs. Capability

In control if it is within natural variability

Is capable if it is entirely within specification

## Process Capability

**Actual Capability:**

$$C_{pk}=min\bigg(\frac{\mu-LSL}{3\sigma},\frac{USL-\mu}{3\sigma}\bigg)$$

**Potential Capability:**

$$C_p = \frac{USL-LSL}{6\sigma}$$

## Reliability Analysis

**Series:**

$$R = \prod_{i=1}^n P_i$$

**Parallel:**

$$R = 1-\prod_{i=1}^n (1-P_i) $$

**Hazard Function**

$$h(x)=\frac{f(x)}{R(x)} \\ f(x) \text{ = density function, } R(x) \text{ = survival function}$$

**Exponential**
$$h(x)=\lambda$$

**Weibull**
$$h(x)=\frac{\beta}{\alpha}\big(\frac{x}{\alpha}\big)^{\beta-1}$$

# Statistics

## Normal Distribution

**z-score**

$$z=\frac{x-\mu}{\sigma}$$

**Confidence Interval**

$$\bar{x}\pm\frac{z_{\alpha/2} \sigma}{\sqrt{n}}$$

**Two-means comparison:**

$$z_0=\frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}$$

## student-t Distribution

**t-score:**

$$t=\frac{\bar{x}-\mu}{\frac{s}{\sqrt{n}}}$$

**Confidence Interval**

$$\bar{x}\pm\frac{t_{\alpha/2,n-1}s}{\sqrt{n}}$$

**Two-means comparison:**

$$t_0=\frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$$

**df for Two Sample t-test:**

$$df=\frac{\big(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}\big)^2}{\frac{(\frac{s_1^2}{n_1})^2}{n_1-1}+{\frac{(\frac{s_1^2}{n_1})^2}{n_1-1}}}$$

## Hypothesis Testing

```{r, warning=FALSE}
x <- seq(-3.5, 3.5, by = .001)
h0Less <- ggplot() + 
  geom_ribbon(aes(x = seq(min(x), qnorm(.05), by = .001),
                  ymin = 0,
                  ymax = dnorm(seq(min(x), qnorm(.05), by = .001))),
              fill = 'gray') +
  geom_vline(xintercept = 0, color = "black") +
  geom_hline(yintercept = 0, color = "black") +
  stat_function(aes(x = x),  
                fun = dnorm, 
                size = 1) +
  geom_segment(aes(x = qnorm(.05),
                   y = 0,
                   xend = qnorm(.05),
                   yend = dnorm(qnorm(.05))
  ),
  #size = 1,
  color = 'black') +
  theme_void() +
  theme(plot.margin = unit(c(.1,.1,.1,.1), "cm")) +
  annotate(geom = 'text',
           x = c(quantile(x, .15),
                 qnorm(.05)),
           y = c(dnorm(qnorm(.25)),
                 -.04),
           label = c(expression(atop(H[0] : mu == mu[0],
                                     H[1] : mu < mu[0])),
                     expression(-z[alpha])),
           size = 4,
           parse = TRUE) +
  coord_cartesian(ylim = c(-.06, dnorm(qnorm(.5))))

h0More <- ggplot() +
  geom_ribbon(aes(x = seq(qnorm(.95), max(x), by = .001),
                  ymin = 0,
                  ymax = dnorm(seq(qnorm(.95), max(x), by = .001))),
              fill = 'gray') +
  geom_vline(xintercept = 0, color = "black") +
  geom_hline(yintercept = 0, color = "black") +
  stat_function(aes(x = x),  
                fun = dnorm, 
                size = 1) +
  geom_segment(aes(x = qnorm(.95),
                   y = 0,
                   xend = qnorm(.95),
                   yend = dnorm(qnorm(.95))
  ),
  #size = 1,
  color = 'black') +
  theme_void() +
  theme(plot.margin = unit(c(.1,.1,.1,.1), "cm")) +
  annotate(geom = 'text',
           x = c(quantile(x, .15),
                 qnorm(.95)),
           y = c(dnorm(qnorm(.25)),
                 -.04),
           label = c(expression(atop(H[0] : mu == mu[0],
                                     H[1] : mu > mu[0])),
                     expression(z[alpha])),
           size = 4,
           parse = TRUE) +
  coord_cartesian(ylim = c(-.06, dnorm(qnorm(.5))))

h0Equal <- ggplot() +
   geom_ribbon(aes(x = seq(min(x), qnorm(.025), by = .001),
                  ymin = 0,
                  ymax = dnorm(seq(min(x), qnorm(.025), by = .001))),
              fill = 'gray') +
    geom_ribbon(aes(x = seq(qnorm(.975), max(x), by = .001),
                  ymin = 0,
                  ymax = dnorm(seq(qnorm(.975), max(x), by = .001))),
              fill = 'gray') +
  geom_vline(xintercept = 0, color = "black") +
  geom_hline(yintercept = 0, color = "black") +
  stat_function(aes(x = x),  
                fun = dnorm, 
                size = 1) +
  geom_segment(aes(x = c(qnorm(.025), qnorm(.975)),
                   y = c(0, 0),
                   xend = c(qnorm(.025), qnorm(.975)),
                   yend = c(dnorm(qnorm(.025)),
                            dnorm(qnorm(.975)))
  ),
  #size = 1,
  color = 'black') +
  theme_void() +
  theme(plot.margin = unit(c(.1,.1,.1,.1), "cm")) +
  annotate(geom = 'text',
           x = c(quantile(x, .15),
                 qnorm(.975),
                 qnorm(.025)),
           y = c(dnorm(qnorm(.25)),
                 -.05,
                 -.05),
           label = c(expression(atop(H[0] : mu == mu[0],
                                     H[1] : mu != mu[0])),
                     expression(z[alpha/2]),
                     expression(-z[alpha/2])),
           size = 4,
           parse = TRUE) +
  coord_cartesian(ylim = c(-.06, dnorm(qnorm(.5))))

multiplot(h0Less, h0More, h0Equal, cols = 3)
```


```{r results = 'asis'}
hypothesisTable <- data.frame(" " = c("$\\text{Accept } H_0$", 
                                      "$\\text{Reject } H_0$"),
                              "$H_0 \\text{ is true}$" = c("Correct",
                                                           "Type I Error"),
                              "$H_0 \\text{ is false}$" = c("Type II Error",
                                                            "Correct"),
                              check.names = FALSE)

hypothesisTable <- xtable(hypothesisTable,
                          caption = "Error Table",
                          align = rep("c", ncol(hypothesisTable)+1))

print(hypothesisTable, 
      type = 'html',
      floating = TRUE,
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.colnames.function = function(x){x},
      sanitize.text.function = function(x) {x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"),
      floating.environment = "sidewaystable")
```

## Chi-Squared Goodness of Fit

$$\chi^2=\sum_{j=1}^k\frac{(O_j-E_j)^2}{E_j}$$

## Linear Regression

$$SSR=\sum_{i=1}^n(\hat{y}_i-\bar{y})^2$$

$$SSE = \sum_{i=1}^n(y_i-\hat{y}_i)^2$$

$$SST = \sum_{i=1}^n(y_i-\bar{y})^2$$

$$R^2=\frac{SSR}{SST} = 1-\frac{SSE}{SST}$$

## ANOVA

$$SSA+SSE=SST$$

**One-Way**

Given Treatment A:

$$SSA+SSE=SST$$

```{r oneway ANOVA}
SS <- c('SSA', 'SSE', 'SST')
df <- c('a-1', 'a(n-1)', 'an-1')
MS <- c('SSA/dfA', 'SSE/dfE', '')
fstat <- c('MSA/MSE', '', '')
anovaTable <- data.frame(SS,
                         df,
                         MS,
                         "F" = fstat)
knitr::kable(anovaTable)
rm(df)
```

**Two-Way**

Given treatment factors A & B:

$$SST=SSA+SSB+SSAB+SSE$$

```{r twoway ANOVA}
SS <- c('SSA', 'SSB', 'SSAB', 'SSE', 'SST')
df <- c('a-1', 'b-1', '(a-1)(b-1)', 'ab(n-1)', 'abn-1')
MS <- c('SSA/dfA', 'SSB/dfB', 'SSAB/dfAB', 'SSE/dfE', '')
fstat <- c('MSA/MSE', 'MSB/MSE', 'MSAB/MSE', '', '')
anovaTable <- data.frame(SS,
                         df,
                         MS,
                         "F" = fstat)
knitr::kable(anovaTable)
rm(df)
```

## Bayesian Analysis

**Bayes' Theorem**

$$P(A|B)=\frac{P(B|A)P(A)}{P(B)}=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^\prime)P(A^\prime)}$$

<p style="page-break-before: always">

## Distributions

```{r results='asis'}
discrete <- c("Binomial", 
              "Discrete Uniform", 
              "Poisson", 
              "Geometric",
              "Negative Binomial")
pmf <- c("$\\binom{n}{x}p^x(1-p)^{n-x}$", 
         "$\\frac{1}{b-a+1}$", 
         "$\\frac{\\lambda^x e^{-\\lambda}}{x!}$", 
         "$p(1-p)^{x}$",
         "$\\binom{k+x-1}{x}p^k(1-p)^x$")
dcdf <- c("$\\sum_{i=0}^{\\lfloor x \\rfloor}\\binom{n}{i}p^i(1-p)^{n-i}$", 
          "$\\frac{\\lfloor x \\rfloor - a + 1}{b-a+1}$", 
          "$e^{-\\lambda}\\sum_{i=0}^{\\lfloor x \\rfloor}\\frac{\\lambda^i}{i!}$", 
          "$1-(1-p)^{x+1}$",
          "$-$") 
dmean <- c("$np$", 
           "$\\frac{a+b}{2}$", 
           "$\\lambda$", 
           "$\\frac{1-p}{p}$",
           "$\\frac{k(1-p)}{p}$")
dvariance <- c("$np(1-p)$", 
               "$\\frac{(b-a+1)^2-1}{12}$", 
               "$\\lambda$", 
               "$\\frac{1-p}{p^2}$",
               "$\\frac{k(1-p)}{p^2}$")
dparameters <- c("$\\text{n = number of trials} \\\\ \\text{p = success probability}$",
                 "$\\text{a = minimum} \\\\ \\text{b = maximum}$", 
                 "$\\lambda\\text{ = rate}$", 
                 "$\\text{k = number of trials} \\\\ \\text{p = success probability}$",
                 "$\\text{k = number of successes}\\\\ \\text{p = success probability}$")
discreteColNames <- c("Distribution", 
                      "pmf", 
                      "cdf", 
                      "mean", 
                      "variance", 
                      "parameters")
discreteDistr <- data.frame(discrete,
                            pmf,
                            dcdf,
                            dmean,
                            dvariance,
                            dparameters,
                            stringsAsFactors = FALSE)
names(discreteDistr) <- discreteColNames

discreteDistr <- xtable(discreteDistr,
                        caption = "Discrete",
                        align = rep("c", ncol(discreteDistr)+1))

print(discreteDistr, 
      type = 'html',
      floating = TRUE,
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.text.function = function(x) {x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"),
      floating.environment = "sidewaystable")
```

```{r continuous distributions table, results = 'asis'}
continuous <- c("Uniform",
                "Exponential",
                "Normal",
                "PERT beta",
                "Triangular",
                "Gamma",
                "Weibull",
                "Lognormal")

pdf <- c("$\\frac{1}{b-a}$",
         "$\\lambda e^{-\\lambda x}$",
         "$\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$",
         "$-$",
         "$\\begin{cases} \\frac{(x-a)^2}{(b-a)(c-a)},\\quad a\\le x\\le c \\\\  1-\\frac{(b-x)^2}{(b-a)(b-c)},\\quad c<x\\le b
\\end{cases}$",
         "$\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\beta x}$",
         "$\\frac{\\beta}{\\alpha}\\binom{x}{\\alpha}^{\\beta-1}e^{-{(\\frac{x}{\\alpha}})^\\beta}$",
         "$\\frac{1}{x\\sigma\\sqrt{2\\pi}}e^{\\frac{(ln x-\\mu)^2}{2\\sigma^2}}$")

ccdf <- c("$\\frac{x-a}{b-a}$",
          "$1-e^{-\\lambda x}$",
          "$\\frac{1}{2}\\big[1+erf\\big(\\frac{x-\\mu}{\\sigma\\sqrt{2}}\\big)\\big]$",
          "$-$",
          "$\\begin{cases} \\frac{(x-a)^2}{(b-a)(c-a)},\\quad a\\le x\\le c \\\\ 1-\\frac{(b-x)^2}{(b-a)(b-c)}, \\quad c<x\\le b
\\end{cases}$",
          "$\\frac{1}{\\Gamma(\\alpha)}\\gamma(\\alpha,\\beta x)$",
          "$1-e^{-(\\frac{x}{\\alpha})^\\beta}$",
          "$\\frac{1}{2}+ \\frac{1}{2} erf \\big[ \\frac{ln x-\\mu}{\\sigma\\sqrt{2}}\\big]$")
cmean <- c("$\\frac{a+b}{2}$",
           "$\\frac{1}{\\lambda}$",
           "$\\mu$",
           "$\\frac{a+4m+b}{6}$",
           "$\\frac{a+b+c}{3}$",
           "$\\alpha\\beta$",
           "$-$",
           "$e^{\\mu+\\frac{\\sigma^2}{2}}$")
cvariance <- c("$\\frac{(b-a)^2}{12}$",
               "$\\frac{1}{\\lambda^2}$",
               "$\\sigma^2$",
               "$\\frac{(b-a)^2}{36}$",
               "$\\frac{a^2+m^2+b^2-ca-ab-cb}{18}$",
               "$\\alpha\\beta^2$",
               "$-$",
               "$[e^{\\sigma^2}-1] e^{2\\mu+\\sigma^2}$")

cparameters <- c("$\\text{a = minimum} \\\\ \\text{b = maximum}$",
                 "$\\lambda \\text{ = rate}$",
                 "$\\mu \\text{ = mean} \\\\ \\sigma^2 \\text{ = variance}$",
                 "$\\text{a = 1st percentile} \\\\ \\text{b = 99th percentile} \\\\ \\text{m = mode}$",
                 "$\\text{a = minimum} \\\\ \\text{b = maximum} \\\\ \\text{c = mode}$",
                 "$\\alpha \\text{ = shape} \\\\ \\beta \\text{ = scale}$",
                 "$-$",
                 "$\\mu\\text{ = mean} \\\\ \\sigma^2 \\text{ = variance}$")

continuousColNames <- c("Distribution", 
                      "pdf", 
                      "cdf", 
                      "mean", 
                      "variance", 
                      "parameters")
continuousDistr <- data.frame(continuous,
                            pdf,
                            ccdf,
                            cmean,
                            cvariance,
                            cparameters,
                            stringsAsFactors = FALSE)
names(continuousDistr) <- continuousColNames

continuousDistr <- xtable(continuousDistr,
                        caption = "Continuous",
                        align = rep("c", ncol(continuousDistr)+1))

print(continuousDistr, 
      type = 'html',
      floating = TRUE,
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.text.function = function(x) {x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"),
      floating.environment = "sidewaystable")
```

<p style="page-break-before: always">

<h2>
$\text{Factors for Control Charts}$
</h2>

```{r fcc, echo = FALSE, results='asis'}
ccf <- read.csv('../data/control_chart_factors.csv')
names(ccf) <- sub("([0-9]{1})", "_\\1", names(ccf))
names(ccf)[names(ccf) %in% "invd_2"] <- "d_2^{-1}"
names(ccf) <- paste0("$", names(ccf), "$")

ccf <- xtable(ccf,
              caption = "Table 1: Factors for Calculating Limits for Variable Control Charts",
                      align = rep("c", ncol(ccf)+1),
                      digits = 3)
print(ccf, 
      type = 'html',
      floating = TRUE,
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.colnames.function = function(x){x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"))
```


<p style="page-break-before: always">

<h2>
$\text{Normal Distribution}$
</h2>

```{r , fig.width=2, fig.height=1.5, warning=FALSE}
ggplot() +
  geom_vline(xintercept = 0, color = "black") +
  geom_hline(yintercept = 0, color = "black") +
  stat_function(aes(x = x),  
                fun = dnorm, 
                size = 1) +
  geom_segment(aes(x = qnorm(.95),
                   y = 0,
                   xend = qnorm(.95),
                   yend = dnorm(qnorm(.95))
  ),
  #size = 1,
  color = 'black') +
  theme_void() +
  theme(plot.margin = unit(c(.1,.1,.1,.1), "cm")) +
  annotate(geom = 'text',
           x = c(qnorm(.95)),
           y = c(-.04),
           label = c(expression(z[alpha])),
           size = 4,
           parse = TRUE) +
  coord_cartesian(ylim = c(-.06, dnorm(qnorm(.5))))
```


```{r Normal Dist Table, results='asis'}
normalTable <- matrix(round(pnorm(seq(0, 3.49, by = .01)), 4), 
                      ncol = 10,
                      byrow = TRUE)
colnames(normalTable) <- seq(0, .09, by = .01)
z <- sprintf("%01.1f", seq(0, 3.4, by = .1))
normalTable <- data.frame("$z$" = paste0("**", z, "**"),
                          normalTable,
                          stringsAsFactors = FALSE)
colnames(normalTable) <- c("z", seq(0, .09, by = .01))
normalTable <- xtable(normalTable,
                      caption = "Table 2: Cumulative Probabilities of the Standard Normal Distribution, $X \\sim N(0,1)$",
                      align = rep("c", ncol(normalTable)+1),
                      digits = 4)
print(normalTable, 
      type = 'html',
      floating = TRUE,
      include.rownames = FALSE,
      caption.placement = "top",
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"),
      floating.environment = "sidewaystable")
```

<p style="page-break-before: always">

<h2>
$t \text{ Distribution}$
</h2>

```{r , fig.width=2, fig.height=1.5, warning=FALSE}
ggplot() +
  geom_vline(xintercept = 0, color = "black") +
  geom_hline(yintercept = 0, color = "black") +
  stat_function(aes(x = x),  
                fun = dnorm, 
                size = 1) +
  geom_segment(aes(x = qnorm(.95),
                   y = 0,
                   xend = qnorm(.95),
                   yend = dnorm(qnorm(.95))
  ),
  #size = 1,
  color = 'black') +
  theme_void() +
  theme(plot.margin = unit(c(.1,.1,.1,.1), "cm")) +
  annotate(geom = 'text',
           x = c(qnorm(.95)),
           y = c(-.04),
           label = c(expression(t[paste(alpha,',',v)])),
           size = 4,
           parse = TRUE) +
  coord_cartesian(ylim = c(-.06, dnorm(qnorm(.5))))
```

```{r t distribution, results='asis'}
alpha <- c(.1, .05, .025, .01, .005)
v <- c(seq(1, 30, by = 1), Inf)
tTable <- sapply((1-alpha), function(x) qt(x, df = v))
colnames(tTable) <- alpha
tTable <- data.frame("$v \\big\\backslash \\alpha$" = paste0("**", v, "**"),
                     tTable,
                     stringsAsFactors = FALSE,
                     check.names = FALSE)
tTable[[1]][tTable[[1]] == "**Inf**"] <- "$\\infty$" 
tTable <- xtable(tTable,
                      caption = "Table 3: Percentiles of the *t* Distribution",
                      align = rep("c", ncol(tTable)+1),
                      digits = 4)
print(tTable, 
      type = 'html',
      floating = TRUE,
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.colnames.function = function(x){x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"),
      floating.environment = "sidewaystable")
```

<p style="page-break-before: always">

<h2>
$\chi^2 \text{ Distribution}$
</h2>

```{r , fig.width=2, fig.height=1.5, warning=FALSE}
x <- seq(0, 30, .01)
v <- 10
ggplot() +
  geom_vline(xintercept = 0, color = "black") +
  geom_hline(yintercept = 0, color = "black") +
  stat_function(aes(x = x),  
                fun = dchisq, 
                args = list(df = v),
                size = 1) +
  geom_segment(aes(x = qchisq(.95, df = v),
                   y = 0,
                   xend = qchisq(.95, df = v),
                   yend = dchisq(qchisq(.95, df = v), df = v)
  ),
  #size = 1,
  color = 'black') +
  theme_void() +
  theme(plot.margin = unit(c(.1,.1,.1,.1), "cm")) +
  annotate(geom = 'text',
           x = c(qchisq(.95, df = v)),
           y = c(-.015),
           label = c(expression( paste(Chi^2)[paste(alpha,',','v')])),
           size = 4,
           parse = TRUE) +
  coord_cartesian(ylim = c(-.02, dchisq(qchisq(.5, df = v), df = v)))
```

```{r chi squared table, results = 'asis', echo=FALSE}
alpha <- c(.995, .99, .975, .95, .9, .75, .5, .25, .1, .05, .025, .01, .005, .001)
v <- c(seq(1, 25, by = 1), seq(30, 100, by = 10))
chiTable <- sapply((1-alpha), function(x) round(qchisq(x, df = v), 2))
colnames(chiTable) <- alpha
chiTable <- data.frame("$v \\big\\backslash \\alpha$" = paste0("**", v, "**"),
                       chiTable,
                       stringsAsFactors = FALSE,
                       check.names = FALSE)
chiTable <- xtable(chiTable,
                      caption = "Table 4: Percentiles of the $\\chi^2$ Distribution",
                      align = rep("c", ncol(chiTable)+1))

print(chiTable, 
      type = 'html',
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.colnames.function = function(x){x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"))
```


<p style="page-break-before: always">

<h2>
$F(v_1, v_2) \text{ Distribution}$
</h2>

```{r , fig.width=2, fig.height=1.5, warning=FALSE}
x <- seq(0, 5, .01)
v1 <- 10
v2 <- 10
ggplot() +
  geom_vline(xintercept = 0, color = "black") +
  geom_hline(yintercept = 0, color = "black") +
  stat_function(aes(x = x),  
                fun = df, 
                args = list(df1 = v1, df2 = v2),
                size = 1) +
  geom_segment(aes(x = qf(.95, df1 = v1, df2 = v2),
                   y = 0,
                   xend = qf(.95, df1 = v1, df2 = v2),
                   yend = df(qf(.95, df1 = v1, df2 = v2), df1 = v1, df2 = v2)
  ),
  #size = 1,
  color = 'black') +
  theme_void() +
  theme(plot.margin = unit(c(.1,.1,.1,.1), "cm")) +
  annotate(geom = 'text',
           x = c(qf(.95, df1 = v1, df2 = v2)),
           y = c(-.07),
           label = c(expression(F(paste(v1,',',v2)))),
           size = 4,
           parse = TRUE) +
  coord_cartesian(ylim = c(-.07, df(qf(.25, df1 = v1, df2 = v2), df1 = v1, df2 = v2)))
```

```{r 95th F Dist, results = 'asis', echo = FALSE}
v1 <- c(seq(1, 10, by = 1), 12, 15, 20, 24, 30, 40, 60, 120, Inf)
v2 <- v1
fTable95 <- sapply(v1, function(x) round(qf(.95, x, v2), 2))
colnames(fTable95) <- v1
colnames(fTable95)[colnames(fTable95) == 'Inf'] <- "$\\infty$"
fTable95 <- data.frame("$v_2 \\big\\backslash v_1$" = paste0("**", v2, "**"),
                       fTable95,
                       stringsAsFactors = FALSE,
                       check.names = FALSE)
fTable95[[1]][fTable95[[1]] == "**Inf**"] <- "$\\infty$"                        
fTable95 <- xtable(fTable95,
                      caption = "Table 5: 95th Percentiles of the $F(v_1,v_2)$",
                      align = rep("c", ncol(fTable95)+1))

print(fTable95, 
      type = 'html',
      #floating = FALSE,
      #tabular.environment="longtable",
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.colnames.function = function(x){x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"),
      floating.environment = "sidewaystable")
```

```{r 99th F Dist, results = 'asis', echo = FALSE}
v1 <- c(seq(1, 10, by = 1), 12, 15, 20, 24, 30, 40, 60, 120, Inf)
v2 <- v1
fTable99 <- sapply(v1, function(x) sprintf("%.2f", round(qf(.99, x, v2), 2)))
fTable99[1, ] <- sprintf("%.0f", as.numeric(fTable99[1, ]), 0)
colnames(fTable99) <- v1
colnames(fTable99)[colnames(fTable99) == 'Inf'] <- "$\\infty$"
fTable99 <- data.frame("$v_2 \\big\\backslash v_1$" = paste0("**", v2, "**"),
                       fTable99,
                       stringsAsFactors = FALSE,
                       check.names = FALSE)
fTable99[[1]][fTable99[[1]] == "**Inf**"] <- "$\\infty$"      
fTable99 <- xtable(fTable99,
                      caption = "Table 6: 99th Percentiles of the $F(v_1,v_2)$",
                      align = rep("c", ncol(fTable99)+1))

print(fTable99, 
      type = 'html',
      include.rownames = FALSE,
      caption.placement = "top",
      sanitize.colnames.function = function(x){x},
      html.table.attributes = list("border='2' cellpadding='15' cellpadding='5' rules ='all' width ='100%'"),
      floating.environment = "sidewaystable")
```
